{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8rvCLeCCssZJ",
      "metadata": {
        "id": "8rvCLeCCssZJ"
      },
      "source": [
        "# Indian Medicinal Plants — YOLOv8 Classification (Ultralytics)\n",
        "Train a YOLOv8 **classification** model on the Kaggle *Indian Medicinal Plant Image Dataset* with clear, step-by-step code and visuals.\n",
        "\n",
        "**What you'll get:**\n",
        "- Dataset download via Kaggle API (or use Google Drive/local path)\n",
        "- Auto **train/val split** if missing\n",
        "- Train **YOLOv8n-cls** with metrics\n",
        "- Visualizations: class distribution, sample grids, training curves, **confusion matrix**, per-class metrics, predictions gallery\n",
        "\n",
        "> Tip: If your Colab disconnects, just re-run from the top — paths are preserved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9LxH72p0ssZN",
      "metadata": {
        "id": "9LxH72p0ssZN"
      },
      "source": [
        "## 0. Runtime & GPU\n",
        "Make sure you're on **Runtime → Change runtime type → T4/A100 GPU** for faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sbiX1D9SssZO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbiX1D9SssZO",
        "outputId": "76828748-1edb-4fe3-ca4c-b06fc9e2c17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "No GPU detected — training will be slower.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys, platform, os, pathlib, subprocess, math, random, shutil, glob, json\n",
        "print(\"Python:\", sys.version)\n",
        "!nvidia-smi || echo \"No GPU detected — training will be slower.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mleUdo3pssZP",
      "metadata": {
        "id": "mleUdo3pssZP"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OkqAwpWzssZQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkqAwpWzssZQ",
        "outputId": "94a13091-b410-47ce-da15-6ec7a23b3004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/82.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m81.9/82.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m878.7/878.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip -q install ultralytics==8.3.25 kaggle==1.6.17 ipywidgets==8.1.2\n",
        "from IPython.display import display, Image as IPyImage, Markdown\n",
        "import os, json, shutil, random, glob, math, pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "print(\"Installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hsCx0-BAssZQ",
      "metadata": {
        "id": "hsCx0-BAssZQ"
      },
      "source": [
        "## 2. Get the Dataset\n",
        "You have two options:\n",
        "\n",
        "### Option A (Recommended): Download directly from Kaggle\n",
        "1. Create a Kaggle API token from **https://www.kaggle.com/settings/account** → *Create New Token* (downloads `kaggle.json`).\n",
        "2. Run the cell below and **upload** your `kaggle.json`.\n",
        "\n",
        "### Option B: Skip Kaggle & use an existing path\n",
        "If you've already uploaded/extracted the dataset to Drive or Colab, set `DATASET_ROOT` manually in the next subsection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LqswNaKNssZR",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "LqswNaKNssZR",
        "outputId": "d3b4e5ed-92ab-419e-d03d-930274d0277a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload kaggle.json (from Kaggle Account settings). If you prefer to skip, cancel and go to Option B cell.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-581d9663-97ef-4041-8ef8-29d0cf97ffa9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-581d9663-97ef-4041-8ef8-29d0cf97ffa9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import os, json, pathlib, shutil\n",
        "from google.colab import files\n",
        "\n",
        "KAGGLE_DATASET_REF = \"warcoder/indian-medicinal-plant-image-dataset\"\n",
        "DATA_DIR = pathlib.Path(\"/content/data_medicinal_plants\")\n",
        "KAGGLE_DIR = pathlib.Path(\"/root/.kaggle\")\n",
        "KAGGLE_JSON = KAGGLE_DIR / \"kaggle.json\"\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "KAGGLE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Upload kaggle.json (from Kaggle Account settings). If you prefer to skip, cancel and go to Option B cell.\")\n",
        "try:\n",
        "    uploaded = files.upload()  # Pop-up file chooser\n",
        "    for fn in uploaded.keys():\n",
        "        if fn == \"kaggle.json\":\n",
        "            with open(KAGGLE_JSON, \"wb\") as f:\n",
        "                f.write(uploaded[fn])\n",
        "            os.chmod(KAGGLE_JSON, 0o600)\n",
        "            print(\"kaggle.json saved.\")\n",
        "except Exception as e:\n",
        "    print(\"Upload skipped or failed:\", e)\n",
        "\n",
        "if KAGGLE_JSON.exists():\n",
        "    !kaggle datasets download -d $KAGGLE_DATASET_REF -p $DATA_DIR --force\n",
        "    # Try common archive names\n",
        "    import zipfile, glob\n",
        "    zips = glob.glob(str(DATA_DIR / \"*.zip\"))\n",
        "    for z in zips:\n",
        "        print(\"Extracting:\", z)\n",
        "        with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DATA_DIR)\n",
        "    print(\"Dataset prepared under:\", DATA_DIR)\n",
        "else:\n",
        "    print(\"No kaggle.json found. Use Option B below to point to your data path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g8clev2zssZS",
      "metadata": {
        "id": "g8clev2zssZS"
      },
      "source": [
        "### Option B: Use an existing dataset path\n",
        "If you already have the dataset extracted (e.g., in Drive), set `DATASET_ROOT` below. The code will attempt to auto-create a **train/val** split if missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vVSGfJzEssZT",
      "metadata": {
        "id": "vVSGfJzEssZT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If you mounted Drive, your path might look like: /content/drive/MyDrive/medicinal_plants\n",
        "# By default, we assume the Kaggle download extracted into DATA_DIR.\n",
        "import pathlib, os, glob\n",
        "\n",
        "DEFAULT_CANDIDATES = [\n",
        "    \"/content/data_medicinal_plants\",\n",
        "    \"/content/data\",\n",
        "    \"/content/drive/MyDrive/medicinal_plants\",\n",
        "    \"/content/drive/MyDrive/datasets/indian_medicinal_plants\"\n",
        "]\n",
        "\n",
        "# Auto-pick an existing directory if found, else keep the first as default.\n",
        "cand = [p for p in DEFAULT_CANDIDATES if os.path.exists(p)]\n",
        "DATASET_ROOT = pathlib.Path(cand[0] if cand else DEFAULT_CANDIDATES[0])\n",
        "print(\"Using DATASET_ROOT:\", DATASET_ROOT)\n",
        "os.makedirs(DATASET_ROOT, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kjJX-hM5ssZT",
      "metadata": {
        "id": "kjJX-hM5ssZT"
      },
      "source": [
        "## 3. Inspect Structure & Create Train/Val Split (if needed)\n",
        "We expect a folder-of-class-folders format. If `train/` and `val/` don't exist, we'll create them (80/20 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-5MKBQwssZU",
      "metadata": {
        "id": "u-5MKBQwssZU"
      },
      "outputs": [],
      "source": [
        "import os, shutil, random, pathlib, glob\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "def is_class_dir_structure(root):\n",
        "    # True if root contains only class subfolders with image files\n",
        "    classes = [p for p in pathlib.Path(root).glob(\"*\") if p.is_dir()]\n",
        "    if not classes:\n",
        "        return False\n",
        "    # Look for images inside at least one class\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}\n",
        "    for c in classes:\n",
        "        imgs = [p for p in c.rglob(\"*\") if p.suffix.lower() in exts]\n",
        "        if imgs:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def ensure_split(root, train_ratio=0.8):\n",
        "    root = pathlib.Path(root)\n",
        "    train_dir, val_dir = root / \"train\", root / \"val\"\n",
        "\n",
        "    # Check if the expected zip file exists, if not, inform the user to download it.\n",
        "    zip_file_path = root / \"indian-medicinal-plant-image-dataset.zip\"\n",
        "    if not zip_file_path.exists():\n",
        "        print(f\"Dataset zip file not found at {zip_file_path}. Please ensure the dataset is downloaded and extracted into the DATASET_ROOT directory.\")\n",
        "        print(\"You can do this by uploading your kaggle.json in the cell above or manually placing the extracted dataset in the DATASET_ROOT path.\")\n",
        "        raise RuntimeError(\"Dataset not found in the expected location. Please download or point to the correct directory.\")\n",
        "\n",
        "\n",
        "    if train_dir.exists() and val_dir.exists():\n",
        "        print(\"train/ and val/ already exist. Skipping split.\")\n",
        "        return train_dir, val_dir\n",
        "\n",
        "    # If the dataset came extracted with a top-level folder, use it\n",
        "    # Try to find a subfolder that is class-structured\n",
        "    candidate = None\n",
        "    for p in root.iterdir():\n",
        "        if p.is_dir() and is_class_dir_structure(p):\n",
        "            candidate = p\n",
        "            break\n",
        "    base = candidate if candidate else root\n",
        "    print(\"Base for split:\", base)\n",
        "\n",
        "    # Collect classes\n",
        "    classes = [p for p in base.iterdir() if p.is_dir()]\n",
        "    if not classes:\n",
        "        raise RuntimeError(\"No class subfolders found. Please set DATASET_ROOT to the folder containing class subfolders.\")\n",
        "\n",
        "    # Prepare train/val\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}\n",
        "    train_dir.mkdir(exist_ok=True)\n",
        "    val_dir.mkdir(exist_ok=True)\n",
        "    for c in classes:\n",
        "        (train_dir / c.name).mkdir(exist_ok=True, parents=True)\n",
        "        (val_dir / c.name).mkdir(exist_ok=True, parents=True)\n",
        "        imgs = [p for p in c.rglob(\"*\") if p.suffix.lower() in exts]\n",
        "        random.shuffle(imgs)\n",
        "        split = int(len(imgs) * train_ratio)\n",
        "        for p in imgs[:split]:\n",
        "            shutil.copy2(p, train_dir / c.name / p.name)\n",
        "        for p in imgs[split:]:\n",
        "            shutil.copy2(p, val_dir / c.name / p.name)\n",
        "        print(f\"Class {c.name}: {len(imgs[:split])} train, {len(imgs[split:])} val.\")\n",
        "    return train_dir, val_dir\n",
        "\n",
        "train_dir, val_dir = ensure_split(DATASET_ROOT)\n",
        "print(\"Train:\", train_dir)\n",
        "print(\"Val:\", val_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YBjBW_y1ssZV",
      "metadata": {
        "id": "YBjBW_y1ssZV"
      },
      "source": [
        "## 4. Visualize Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jedJSaSPssZW",
      "metadata": {
        "id": "jedJSaSPssZW"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, pathlib, collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def count_images(folder):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}\n",
        "    counts = {}\n",
        "    for cls in sorted([p for p in pathlib.Path(folder).glob(\"*\") if p.is_dir()]):\n",
        "        n = sum(1 for p in cls.rglob(\"*\") if p.suffix.lower() in exts)\n",
        "        counts[cls.name] = n\n",
        "    return counts\n",
        "\n",
        "train_counts = count_images(train_dir)\n",
        "val_counts = count_images(val_dir)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(len(train_counts)), list(train_counts.values()))\n",
        "plt.xticks(range(len(train_counts)), list(train_counts.keys()), rotation=90)\n",
        "plt.title(\"Training set class distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(len(val_counts)), list(val_counts.values()))\n",
        "plt.xticks(range(len(val_counts)), list(val_counts.keys()), rotation=90)\n",
        "plt.title(\"Validation set class distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QVGF7LxAssZW",
      "metadata": {
        "id": "QVGF7LxAssZW"
      },
      "source": [
        "## 5. Peek at Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90PlYC2rssZW",
      "metadata": {
        "id": "90PlYC2rssZW"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random, pathlib\n",
        "\n",
        "def sample_images(folder, n=16):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}\n",
        "    imgs = [p for p in pathlib.Path(folder).rglob(\"*\") if p.suffix.lower() in exts]\n",
        "    return random.sample(imgs, min(n, len(imgs)))\n",
        "\n",
        "samples = sample_images(train_dir, n=16)\n",
        "cols = 4\n",
        "rows = max(1, (len(samples) + cols - 1)//cols)\n",
        "plt.figure(figsize=(12, 3*rows))\n",
        "for i, p in enumerate(samples, 1):\n",
        "    plt.subplot(rows, cols, i)\n",
        "    img = Image.open(p).convert(\"RGB\")\n",
        "    plt.imshow(img)\n",
        "    plt.title(p.parent.name)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xz6_te-OssZX",
      "metadata": {
        "id": "xz6_te-OssZX"
      },
      "source": [
        "## 6. Train YOLOv8n-cls\n",
        "We use Ultralytics' YOLOv8 **classification** model. You can adjust `epochs` and `imgsz` as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y9pnppNGssZX",
      "metadata": {
        "collapsed": true,
        "id": "y9pnppNGssZX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 classification model\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "# Train on dataset\n",
        "results = model.train(\n",
        "    data=str(DATASET_ROOT),\n",
        "    epochs=15,\n",
        "    imgsz=224,\n",
        "    batch=32,\n",
        "    device=0 if torch.cuda.is_available() else 'cpu'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NTT_W6_hssZY",
      "metadata": {
        "id": "NTT_W6_hssZY"
      },
      "source": [
        "## 7. Training Curves & Metrics\n",
        "Ultralytics saves plots under `runs/classify/train/`. We’ll display the most useful ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KK1hJ85gssZY",
      "metadata": {
        "id": "KK1hJ85gssZY"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob, os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "run_dirs = sorted(glob.glob(\"runs/classify/*\"), key=os.path.getmtime)\n",
        "latest_run = run_dirs[-1]\n",
        "print(\"Latest run:\", latest_run)\n",
        "\n",
        "plot_files = [\n",
        "    \"results.png\",          # loss/accuracy curves\n",
        "    \"confusion_matrix.png\", # confusion matrix\n",
        "]\n",
        "for pf in plot_files:\n",
        "    p = os.path.join(latest_run, pf)\n",
        "    if os.path.exists(p):\n",
        "        display(IPyImage(filename=p))\n",
        "    else:\n",
        "        print(\"Missing plot:\", pf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-xJ9E8jssZZ",
      "metadata": {
        "id": "m-xJ9E8jssZZ"
      },
      "source": [
        "## 8. Validate & Show Per-Class Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NpXrOrUDssZZ",
      "metadata": {
        "id": "NpXrOrUDssZZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "metrics = model.val(split='val', imgsz=224, device=0 if torch.cuda.is_available() else 'cpu', save_json=True)\n",
        "print(metrics)\n",
        "\n",
        "# Try reading per-class metrics from Ultralytics JSON (if available)\n",
        "import json, glob, os\n",
        "json_candidates = glob.glob(os.path.join(latest_run, \"metrics\", \"*.json\")) + glob.glob(os.path.join(latest_run, \"*.json\"))\n",
        "for jc in json_candidates:\n",
        "    if os.path.basename(jc).startswith(\"results\") or os.path.basename(jc).startswith(\"metrics\"):\n",
        "        with open(jc, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        print(\"Loaded metrics JSON:\", jc)\n",
        "        break\n",
        "\n",
        "# Display a simple per-class accuracy table if available\n",
        "try:\n",
        "    from pandas import DataFrame\n",
        "    # Fall back: build confusion-based per-class accuracy if confusion matrix npy exists\n",
        "    cm_npy = os.path.join(latest_run, \"confusion_matrix.npy\")\n",
        "    if os.path.exists(cm_npy):\n",
        "        import numpy as np\n",
        "        cm = np.load(cm_npy)\n",
        "        per_class_acc = (cm.diagonal() / cm.sum(axis=1)).tolist()\n",
        "        # Get class names from data.yaml if present\n",
        "        names_txt = os.path.join(latest_run, \"labels.txt\")\n",
        "        if os.path.exists(names_txt):\n",
        "            with open(names_txt, \"r\") as f:\n",
        "                names = [x.strip() for x in f.readlines() if x.strip()]\n",
        "        else:\n",
        "            # Try to infer from train_dir\n",
        "            names = sorted([p.name for p in pathlib.Path(train_dir).glob(\"*\") if p.is_dir()])\n",
        "        df = DataFrame({\"class\": names, \"accuracy\": per_class_acc})\n",
        "        display(df.head(20))\n",
        "    else:\n",
        "        print(\"No confusion_matrix.npy available to compute per-class accuracy.\")\n",
        "except Exception as e:\n",
        "    print(\"Per-class metrics table not available:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nQ55uxCBssZa",
      "metadata": {
        "id": "nQ55uxCBssZa"
      },
      "source": [
        "## 9. Inference & Prediction Gallery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XPTzoRKcssZa",
      "metadata": {
        "id": "XPTzoRKcssZa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Collect a small sample from val set for inference preview\n",
        "sample_val = []\n",
        "for cls in sorted([p for p in pathlib.Path(val_dir).glob(\"*\") if p.is_dir()]):\n",
        "    candidates = list(cls.glob(\"*\"))\n",
        "    if candidates:\n",
        "        sample_val.extend(random.sample(candidates, min(3, len(candidates))))\n",
        "sample_val = sample_val[:24]\n",
        "\n",
        "preds = model.predict(source=[str(p) for p in sample_val], imgsz=224, device=0 if torch.cuda.is_available() else 'cpu')\n",
        "# preds is a list of Results; for classification, probs & names are available\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cols = 4\n",
        "rows = max(1, (len(sample_val)+cols-1)//cols)\n",
        "plt.figure(figsize=(12, 3*rows))\n",
        "for i, (p, r) in enumerate(zip(sample_val, preds), 1):\n",
        "    plt.subplot(rows, cols, i)\n",
        "    img = Image.open(p).convert(\"RGB\")\n",
        "    plt.imshow(img)\n",
        "    top_idx = int(np.argmax(r.probs.data.cpu().numpy()))\n",
        "    top_name = r.names[top_idx]\n",
        "    top_prob = float(r.probs.data[top_idx])\n",
        "    plt.title(f\"GT: {p.parent.name}\\nPred: {top_name} ({top_prob:.2f})\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tNFz9g2-ssZb",
      "metadata": {
        "id": "tNFz9g2-ssZb"
      },
      "source": [
        "## 10. Export Best Model\n",
        "We’ll save the best weights path and show where to find it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iFOUQgI8ssZb",
      "metadata": {
        "id": "iFOUQgI8ssZb"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_weights = os.path.join(latest_run, \"weights\", \"best.pt\")\n",
        "print(\"Best weights saved at:\", best_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iZuewayDssZb",
      "metadata": {
        "id": "iZuewayDssZb"
      },
      "source": [
        "## (Optional) Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O-2BBsztssZc",
      "metadata": {
        "id": "O-2BBsztssZc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !mkdir -p /content/drive/MyDrive/medicinal_plants_yolov8_runs\n",
        "# !cp -r \"$latest_run\" \"/content/drive/MyDrive/medicinal_plants_yolov8_runs/\"\n",
        "# print(\"Copied run folder to Drive.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}